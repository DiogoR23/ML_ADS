{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Inicial de um Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-análise de um Dataframe\n",
    "def dataframe_macro_analysis(dataframe):\n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    num_rows, num_cols = df.shape\n",
    "    print(\"1) The dataframe has \", num_rows, \" lines and \", num_cols, \" variables.\")\n",
    "\n",
    "    print(\"2) The dataframe has the following structure: \")\n",
    "    print(df.info())\n",
    "\n",
    "    print(\"3) The dataframe includes the following variables: \")\n",
    "    print(dataframe.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta função, **dataframe_macro_analysis**, recebe como entrada um dataFrame e faz uma microanálise, isto é:\n",
    "  - Para a primeira linha passamos o conjunto de Dados recebido para Data Frame;\n",
    "  - Na segunda linha, mostramos quantas linhas e colunas que esse Data Frame é composto;\n",
    "  - Na terceira linha, mostramos a estrutura desse Data Frame, dizendo os nomes de cada coluna e o tipo dela, String, inteiro, character, float, double etc, e mostrando os primeiros valores dessa coluna;\n",
    "  - Na última linha mostramos o nome de cada variável (coluna).\n",
    "\n",
    "# Exemplo de Uso:   dataframe_macro_analysis(nome do dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas Categóricas\n",
    "import pandas as pd\n",
    "\n",
    "def categorical_statistics(dataframe) :\n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    cat_vars = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "    cat_tables = {}\n",
    "    for var in cat_vars:\n",
    "        mode = df[var].mode().iloc[0]\n",
    "        freq_table = df[var].value_counts().reset_index()\n",
    "        freq_table.columns = ['values', 'frequency']\n",
    "        freq_table = freq_table.sort_values(by = 'frequency', ascending = False)\n",
    "        prop_missing = df[var].isna().mean()\n",
    "\n",
    "        cat_tables[vars] = {\n",
    "            'mode' : mode,\n",
    "            'freq_table' : freq_table,\n",
    "            'prop_missing' : prop_missing\n",
    "        }\n",
    "\n",
    "        return {'categorical_tables' : cat_tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta função, **categorical_statistics**, recebe como entrada um Data Frame, retornando as estatísticas de todas as variaveis categóricas desse Data Frame.\n",
    "\n",
    "# Exemplo de uso:   categorical_statistics(nome do dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmar valores omissos\n",
    "import pandas as pd\n",
    "\n",
    "def confirm_missing(dataframe):\n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    num_NA = df.isnull().sum().sum()\n",
    "\n",
    "    if num_NA <= 0:\n",
    "        print(\"The dataframe does not have missing data (NAs)\")\n",
    "    else:\n",
    "        print(\"The dataframe has missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta função, **confirm_missing**, recebe como entrada um Data Frame, e diz-nos se esse tem ou não dados omissos.\n",
    "\n",
    "*Nota:* Se o resultado for **\"This dataFrame has missing data (NA)!\"**, então usamos a função dropna, para dar-nos uma tabela sem esses dados. Caso contrário não é necessário chamar a função, sendo que o conjunto de dados original não tem dados omissos.\n",
    "\n",
    "# Exemplo de uso:   confirm_missing(nome do dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmar duplicados\n",
    "import pandas as pd\n",
    "\n",
    "def confirm_duplicated(dataframe):\n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    x = df.duplicated().sum()\n",
    "    if x > 0:\n",
    "        print(\"The dataframe has duplicate data.\")\n",
    "    else:\n",
    "        print(\"The dataframe doesn't have duplicate data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta função, **confirm_duplicated**, recebe como entrada um dataframe, e diz-nos se esse tem ou não dados duplicados.\n",
    "\n",
    "*NOTA:* Se o resultado for **The dataframe has duplicate data**, então usamos a função drop_duplicated, para ter uma nova tabela sem os dados duplicados.\n",
    "\n",
    "# Exemplode uso:    confirm_duplicated(nome do dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter Variáveis\n",
    "import pandas as pd\n",
    "\n",
    "def convert_dataframe_variables(data, var_names, to_type='integer'):\n",
    "    data =pd.DataFrame(data)\n",
    "    df = data.copy()\n",
    "\n",
    "    conversion_functions = {\n",
    "        'integer': int,\n",
    "        'logical': bool,\n",
    "        'numeric': float,\n",
    "        'character': str,\n",
    "        'ordered': lambda x: pd.Categorical(x, ordered=True),\n",
    "        'factor': lambda x: pd.Categorical(x)\n",
    "    }\n",
    "\n",
    "    conversion_function = conversion_functions.get(to_type)\n",
    "\n",
    "    if conversion_function is None:\n",
    "        raise ValueError('Invalid data type specified!')\n",
    "    \n",
    "    for var_name in var_names:\n",
    "        df[var_name] = df[var_name].map(conversion_function)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciclical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def CyclicalEncoding(dataset, variable, position):\n",
    "    feature = dataset[variable]\n",
    "\n",
    "    num_month = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "\n",
    "    # Map the months to numbers from 1 to 12\n",
    "    map_month = feature.map(num_month)\n",
    "    \n",
    "    # Insert Numeric month feature into de Dataset\n",
    "    dataset.insert(loc=position, column='num_month', value=map_month)\n",
    "\n",
    "    # Apply Cyclical Encoding\n",
    "    month_sin = np.sin(2 * np.pi * dataset['num_month'] / 12)\n",
    "    month_cos = np.cos(2 * np.pi * dataset['num_month'] / 12)\n",
    "    \n",
    "    # Insert the new features into de Dataset\n",
    "    dataset.insert(loc=position, column='month_sin', value=month_sin)\n",
    "    dataset.insert(loc=(position+1), column=\"month_cos\", value=month_cos)\n",
    "\n",
    "    # Removing the num_month and original features from the dataset\n",
    "    dataset = dataset.drop(columns=('num_month', variable))\n",
    "    \n",
    "    # Returning the dataset with the cyclical encoding\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta função, faz um encoding no dataset para uma variável que caracteriza os meses. Isto é, primeiramento cria-se um dicionário com os vários meses do ano, de seguida mapeamos a variável que desejamos encodar (Tem de ser uma variável de meses e de preferência que esteja por extenso), ou seja, criamos uma variável nova onde os meses em vez de estar por extenso está numérica. De seguida aplicamos o tal **Cyclical Encoding**, onde criamos duas variável *seno* e *cosseno*, pois se olharmos no lado de matemática trigonométrica, vemos que na circunferência trigonométrica, o seno é o eixo do y e o cosseno o eixo do x, e que estas duas novas variáveis representam as coordenadas desse ponto de maneira que que o mês de dezembro fica mais perto de janeiro que março fica de janeiro. Para finalizar, adicionamos essas duas variáveis ao dataset como features, e removemos a features original e a que nos mostra os meses em numérico, sendo que já temos as coordenadas trigonométricas que representam os meses.\n",
    "\n",
    "\n",
    "***IMPORTANTE:***\n",
    "\n",
    "- Só devemos usar esta função para variável que representam os meses, e que de preferência estejam por extenso.\n",
    "- Esta função recebe como entrada, o dataset, a variável que representa os meses, e a posição que desejamos colocar estas duas novas variáveis.\n",
    "- Devemos também dar uma variável a esta funçao, por exemplo:\n",
    "```Python\n",
    "new_df = CyclicalEncoding(df, var, pos)\n",
    "```\n",
    "Onde new_df, é o nome que queremos dar ao nosso novo dataset, df o nome do nosso antigo dataset, var o nome da variável que queremos fazer o encoding, e pos a posição que desejamos adicionar as duas novas features.       \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ADS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
